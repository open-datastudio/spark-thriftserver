kind: ConfigMap
apiVersion: v1
metadata:
  name: spark-conf
data:
  spark-container-image: opendatastudio/spark:v3.1.0-snapshot-20200618-01
  spark-defaults.conf: |
    spark.executor.cores                                          4
    spark.executor.memory                                         8g
    spark.dynamicAllocation.enabled                               true
    spark.dynamicAllocation.minExecutors                          1
    spark.dynamicAllocation.maxExecutors                          10
    spark.dynamicAllocation.initialExecutors                      1
    spark.dynamicAllocation.shuffleTracking.enabled               true
    spark.dynamicAllocation.executorIdleTimeout                   600s
    spark.dynamicAllocation.schedulerBacklogTimeout               60s

    # 'dedicated' for dedicated kubernetes node. 'dedicated' or 'sandboxed'
    spark.kubernetes.executor.label.pod.staroid.com/isolation     dedicated

    # 'standard-2', 'standard-4', 'standard-8' available. Note that spark.executor.cores|memory need to be changed accordingly.
    spark.kubernetes.executor.label.pod.staroid.com/instance-type standard-4

    # 'true' for spot instance. 'true' or 'false'
    spark.kubernetes.executor.label.pod.staroid.com/spot          true

    spark.scheduler.mode                                          FAIR
    spark.serializer                                              org.apache.spark.serializer.KryoSerializer
    spark.sql.adaptive.enabled                                    true
    spark.sql.adaptive.coalescePartitions.enabled                 true
  run-thrift-server.sh: |
    #!/bin/bash
    $SPARK_HOME/sbin/start-thriftserver.sh \
      --properties-file $SPARK_CONF_DIR/spark-defaults.conf \
      -c spark.hadoop.hive.metastore.uris=thrift://$HIVE_METASTORE_SERVICE.$HIVE_METASTORE_NAMESPACE:9083 \
      -c spark.kubernetes.namespace=$SPARK_NAMESPACE \
      -c spark.kubernetes.container.image=$SPARK_CONTAINER_IMAGE \
      -c spark.driver.bindAddress=0.0.0.0 \
      -c spark.driver.host=spark-thriftserver \
      -c spark.driver.port=22321 \
      -c spark.blockManager.port=22322 \
      -c spark.master=k8s://https://kubernetes.default.svc \
      -c spark.sql.catalogImplementation=hive

    tail -F /tmp/log/spark/* &

    ps -ef | grep org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 > /dev/null
    RUNNING=$?

    while [ $RUNNING -eq 0 ]; do
      sleep 10
      ps -ef | grep org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 | grep -v grep > /dev/null
      RUNNING=$?
    done
